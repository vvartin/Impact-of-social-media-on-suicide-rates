{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provenance of the files is done via md5 hash comparison of the user generated and reference files.\n",
    "\n",
    "The structure of this file follows the order of the generation of intermediate files by the **preprocess.ipnyb** file located in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROVENANCE_FOLDER_BASE=\"../data/produced/provenance/\"\n",
    "REFERENCE_FOLDER_BASE = PROVENANCE_FOLDER_BASE + \"reference/\"\n",
    "TIMESTAMP_FORMAT = \"%d-%m-%Y-%H-%M-%S\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files generated by the original research are located in **REFERENCE_FOLDER_BASE** and the files generated during the last run are stored in **PROVENANCE_FOLDER_BASE**.\n",
    "\n",
    "During the checks the latest user generated files are compared against the reference files and this depends on the naming convention, see README.md at the root of the project. **Please ensure there are no additional files matching the prefixes of the genreated fils as the latest produced file will fail**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper methods to locate the latest file, calculate the MD5 hash, check whether the hashes match\n",
    "\n",
    "def findFilesStartingWith(prefix):\n",
    "    matchingFiles = []\n",
    "    for file in os.listdir(PROVENANCE_FOLDER_BASE):\n",
    "        if file.startswith(prefix):\n",
    "            matchingFiles.append(file)\n",
    "    return matchingFiles\n",
    "\n",
    "def extractTimestams(files):\n",
    "    timestamps = []\n",
    "    for file in files:\n",
    "        stringTimestamp = file.split(\"--\")[1] # separate the filename out\n",
    "        stringTimestamp = stringTimestamp [:-4] # remove the csv suffix\n",
    "        timestamp = time.strptime(stringTimestamp, TIMESTAMP_FORMAT)\n",
    "        timestamps.append(timestamp)\n",
    "    return timestamps\n",
    "\n",
    "def findLatestFileStartingWith(prefix):\n",
    "    matchingFiles = findFilesStartingWith(prefix)\n",
    "    timestamps = extractTimestams(matchingFiles)\n",
    "    return matchingFiles[timestamps.index(max(timestamps))] if len(timestamps) > 0 else None\n",
    "\n",
    "def calculateMd5HasForFile(file):\n",
    "    fileHandle = open(file, \"rb\")\n",
    "    fileContent = fileHandle.read()\n",
    "    md5Hash = hashlib.md5()\n",
    "    md5Hash.update(fileContent)\n",
    "    return md5Hash\n",
    "\n",
    "def guardFileFound(file, fileName):\n",
    "    if file is None:\n",
    "        raise Exception(\"No produced file for prefix '\" + fileName + \"' was found. Have you run the preprocess.ipnyb successfully?\"  )\n",
    "\n",
    "def compareUserAndReferenceFiles(fileName):\n",
    "    # latest user produced file\n",
    "    latestFile = findLatestFileStartingWith(fileName)\n",
    "    guardFileFound(latestFile, fileName)\n",
    "    producedFileMd5Hash = calculateMd5HasForFile(PROVENANCE_FOLDER_BASE + latestFile)\n",
    "    print(\"Latest produced file:\", latestFile)\n",
    "\n",
    "    # reference file\n",
    "    referenceFile = REFERENCE_FOLDER_BASE + fileName + '.csv'\n",
    "    print(\"Reference file:\", referenceFile)\n",
    "    referenceFileMd5Hash = calculateMd5HasForFile(referenceFile)\n",
    "    \n",
    "    print(\"Latest produced file hash:\", producedFileMd5Hash.hexdigest())\n",
    "    print(\"Reference file hash:      \", referenceFileMd5Hash.hexdigest())\n",
    "    \n",
    "    # match validation\n",
    "    if producedFileMd5Hash.hexdigest() == referenceFileMd5Hash.hexdigest():\n",
    "        print(\"[OK]  HASHES MATCH, files are the same\")\n",
    "    else:\n",
    "        print(\"[ERROR] HASHES DO NOT MATCH!\")\n",
    "        raise Exception(\"Hash mismatch - compare the files: data/provenance/\" + latestFile + \" and data/provenance/reference/\" + fileName + '.csv for differences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social media users yearly aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest produced file: social-media-users-year-aggregated--19-04-2021-20-28-25.csv\n",
      "Reference file: ../data/produced/provenance/reference/social-media-users-year-aggregated.csv\n",
      "Latest produced file hash: 7c6a3d4a1559e3e2f70ee2dc30053c8d\n",
      "Reference file hash:       7c6a3d4a1559e3e2f70ee2dc30053c8d\n",
      "[OK]  HASHES MATCH, files are the same\n"
     ]
    }
   ],
   "source": [
    "fileName = \"social-media-users-year-aggregated\"\n",
    "compareUserAndReferenceFiles(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social media after finall preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest produced file: social-media-users-final-preprocessed--19-04-2021-20-28-25.csv\n",
      "Reference file: ../data/produced/provenance/reference/social-media-users-final-preprocessed.csv\n",
      "Latest produced file hash: a2404d696bbba9d043ec946353224a10\n",
      "Reference file hash:       a2404d696bbba9d043ec946353224a10\n",
      "[OK]  HASHES MATCH, files are the same\n"
     ]
    }
   ],
   "source": [
    "fileName = \"social-media-users-final-preprocessed\"\n",
    "compareUserAndReferenceFiles(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suicide rates without missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"suicide-rates-sanitized\"\n",
    "compareUserAndReferenceFiles(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suicide rates aggregated by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"suicide-rates-aggregated-by-year\"\n",
    "compareUserAndReferenceFiles(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 2 preprocessed datasets merged into 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"merged-datasets\"\n",
    "compareUserAndReferenceFiles(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = \"final-dataset\"\n",
    "compareUserAndReferenceFiles(fileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no exceptions were thrown then all of the files match and the results should be reproducible correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
